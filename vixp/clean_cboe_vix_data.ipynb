{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIX Raw  CBOE  -  Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html, HTML\n",
    "import pyfolio as pf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "from time import time\n",
    "import feather\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "opt_path = '/Users/ebellord/PycharmProjects/opt_trade'\n",
    "if  opt_path not in sys.path:\n",
    "    sys.path.append(opt_path)\n",
    "from ftplib import FTP\n",
    "\n",
    "from spx_data_update import data_shop_login, UpdateSP500Data\n",
    "from option_utilities import write_feather\n",
    "from vix_utilities import UpdateVIXData\n",
    "order_string = '/order_000008108/item_000010804/'\n",
    "data_directory = UpdateSP500Data.DATA_BASE_PATH / 'CBOERawVixData'\n",
    "zip_directory, csv_directory, feather_directory = [data_directory / item for item in ['zip', 'csv','feather']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw zip files - Unpack to CSV and save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_data = UpdateVIXData()\n",
    "download_raw_zip = False\n",
    "if download_raw_zip:\n",
    "    vx_data.download_cboe_vix()\n",
    "raw_df = vx_data.raw_df\n",
    "price_columns = ['open_bid', 'open_ask', 'avg_bid', 'avg_ask','close_bid',\n",
    "                 'close_ask', 'open_px', 'close_px','low_px', 'high_px']                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.loc[:, ['quote_date', 'expiry']] = raw_df.loc[:, ['quote_date', 'expiry']].apply(pd.to_datetime)\n",
    "# Clean prices\n",
    "last_bad_price_date = pd.to_datetime('23-March-2007') # Prior to last_bad_price_date quotes were of the type VIX*10\n",
    "def divide_prices(group):\n",
    "    if all(group['quote_date'] <= last_bad_price_date):\n",
    "           group[price_columns] = group[price_columns] /10\n",
    "    return group\n",
    "clean_price_df = raw_df.groupby(['quote_date']).apply(divide_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of singletons - 1\n"
     ]
    }
   ],
   "source": [
    "# Remove days with only a single traded contract\n",
    "singleton_idx = clean_price_df.groupby(['quote_date']).apply(lambda x: x['quote_date'].count()==1)\n",
    "list_singletons= singleton_idx[singleton_idx].index.strftime('%Y-%m-%d').tolist()\n",
    "print('Number of singletons - {}'.format(len(list_singletons)))\n",
    "for items in list_singletons:\n",
    "    clean_price_df = clean_price_df[clean_price_df['quote_date'] != items]\n",
    "\n",
    "#### WARNING: ELIMINATE SINGLE DATE 15-SEP-2006 #####\n",
    "clean_price_df = clean_price_df[clean_price_df['quote_date'] != '15-09-2006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into good_children where expiry matched actual_expiries and problem_children that do not\n",
    "expiries = pd.DatetimeIndex(raw_df['expiry'].unique())\n",
    "actual_expiries = pd.DatetimeIndex(pd.read_csv(data_directory / 'monthly_expirations.csv',\n",
    "                                                  header=None,\n",
    "                                                  squeeze=True))\n",
    "is_not_actual_expiry = clean_price_df['expiry'].apply(lambda x: x not in actual_expiries)\n",
    "problem_children = clean_price_df[is_not_actual_expiry]\n",
    "good_children = clean_price_df[is_not_actual_expiry.apply(lambda x: not(x))]\n",
    "problem_expiries = pd.DatetimeIndex(problem_children['expiry'].unique()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of problem children - 7054\n",
      "Number of problem expiries - 190\n",
      "Number of problem children - 2534\n",
      "Number of problem expiries - 41\n"
     ]
    }
   ],
   "source": [
    "# Remove weeklies\n",
    "print('Number of problem children - {}'.format(len(problem_children)))\n",
    "print('Number of problem expiries - {}'.format(len(problem_expiries)))\n",
    "wednesday_expiries = [pd.date_range('5 August 2015', actual_expiries[-1],\n",
    "                                    freq=item) for item in ['1W-WED',\n",
    "                                                            '2W-WED',\n",
    "                                                            '4W-WED',\n",
    "                                                            '5W-WED']]\n",
    "all_wed_expiries = pd.to_datetime([])\n",
    "for item in wednesday_expiries:\n",
    "    all_wed_expiries = all_wed_expiries.union(item)\n",
    "\n",
    "irregular_expiries =pd.DatetimeIndex([\n",
    "'24 November 2015', #(Tuesday, due to Christmas Day on Friday)\n",
    "'1 December 2015', #(Tuesday, due to New Year’s Day on Friday)\n",
    "'23 February 2016', #(Tuesday, due to Good Friday)\n",
    "'14 March 2017', #(Tuesday, due to Good Friday)\n",
    "'27 February 2018', #(Tuesday, due to Good Friday)\n",
    "'3 July 2018', #(Tuesday, due to 4 July on Wednesday)\n",
    "'24 December 2019', #(Tuesday, due to Christmas Day on Wednesday, to be confirmed)\n",
    "'31 December 2019']) #(Tuesday, due to New Year’s Day on Wednesday, to be confirmed)\n",
    "all_wed_expiries = all_wed_expiries.union(irregular_expiries)\n",
    "# remove wednesday expiries\n",
    "is_not_wed_expiry = problem_children['expiry'].apply(lambda x: x not in all_wed_expiries)\n",
    "problem_children = problem_children[is_not_wed_expiry]\n",
    "print('Number of problem children - {}'.format(len(problem_children)))\n",
    "problem_expiries = pd.DatetimeIndex(problem_children['expiry'].unique()).sort_values()\n",
    "problem_expiries.sort_values()\n",
    "values = []\n",
    "# Create dictionnary of missmatched expiries (keys) and actual expiries (values)\n",
    "for item in problem_expiries:\n",
    "    idx = np.abs(item - actual_expiries).argmin()\n",
    "    values.append(actual_expiries[idx])\n",
    "expiry_dict = {}\n",
    "keys = problem_expiries\n",
    "for key, value in zip(keys, values):\n",
    "    expiry_dict[key] = value\n",
    "print('Number of problem expiries - {}'.format(len(expiry_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for missing expiries \n",
    "missing_dict = {}\n",
    "missing_key = []\n",
    "missing_value = []\n",
    "# Dictionary for double expiries \n",
    "double_dict = {}\n",
    "double_key = []\n",
    "double_value = []\n",
    "\n",
    "for key, value in expiry_dict.items():\n",
    "    validation_df = clean_price_df[clean_price_df['expiry']==expiry_dict[key]]\n",
    "    if validation_df.empty:\n",
    "        missing_key.append(key)\n",
    "        missing_value.append(value)\n",
    "    else:\n",
    "        double_key.append(key)\n",
    "        double_value.append(value)\n",
    "        \n",
    "for key, value in zip(missing_key, missing_value):\n",
    "    missing_dict[key] = value\n",
    "\n",
    "for key, value in zip(double_key, double_value):\n",
    "    double_dict[key] = value\n",
    "    \n",
    "problem_children = problem_children.replace({'expiry': missing_dict})\n",
    "# Second replacement could be combined with previous replacement however, I choose to split it \n",
    "# into two operations to underline the difference betwee the two replacements\n",
    "problem_children = problem_children.replace({'expiry': double_dict})\n",
    "# Remove single observation where expiry date is equal to quote date\n",
    "index_same_expiry_quote_date = problem_children[problem_children['expiry'] == problem_children['quote_date']].index\n",
    "problem_children_reformed = problem_children.drop(index_same_expiry_quote_date)\n",
    "\n",
    "clean_monthly_future = pd.concat([good_children, problem_children_reformed], axis=0, ignore_index=True)\n",
    "# Make sure clean_monthly_future only has actual expiries\n",
    "assert(pd.DatetimeIndex(clean_monthly_future['expiry'].unique()).difference(actual_expiries).empty)\n",
    "clean_monthly_future['days_left'] = clean_monthly_future['expiry'] - clean_monthly_future['quote_date']\n",
    "\n",
    "# Mannual routine to check last problem children\n",
    "# num = 8\n",
    "# display(foobar[foobar['expiry']==list(double_dict.keys())[num]].sort_values('quote_date'))\n",
    "\n",
    "# display(clean_price_df[clean_price_df['expiry']==list(double_dict.values())[num]].sort_values('quote_date').style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack futures by quote date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_group(group):\n",
    "    column_names  = price_columns + ['expiry', 'days_left']\n",
    "    tmp_list = []\n",
    "    count = 1\n",
    "    one_day = pd.timedelta_range(start='1 day', periods=1)\n",
    "    for item in group['days_left'].sort_values():\n",
    "        if item >= one_day: # remove zero days to expiry\n",
    "            n_expiry_data = group[group['days_left']==item]\n",
    "            n_expiry_data = n_expiry_data[price_columns + ['expiry','days_left']]\n",
    "            n_expiry_data = n_expiry_data.stack(dropna=False)\n",
    "            n_expiry_data.index = n_expiry_data.index.droplevel()\n",
    "            n_expiry_data = n_expiry_data.fillna({'open_px':n_expiry_data[['open_bid', 'open_ask']].mean(),\n",
    "                                                'close_px':n_expiry_data[['close_bid', 'close_ask']].mean()})\n",
    "            n_expiry_data['days_left'] = n_expiry_data['days_left'].days\n",
    "            n_expiry_data.index = [str(col) + str(count) for col in n_expiry_data.index]\n",
    "            count = count + 1\n",
    "            tmp_list.append(n_expiry_data)\n",
    "    stacked_df = pd.concat(tmp_list, ignore_index=False, axis=0)\n",
    "    return stacked_df\n",
    "%time stacked_futures = clean_monthly_future.groupby('quote_date').apply(squeeze_group)\n",
    "vix_data = stacked_futures.unstack(level=1)\n",
    "vix_data = vix_data.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy up and save:\n",
    " - Creating dataframe of vix numbered futures creates a problem when there is missing data. The squeeze_group function applied to each quote_date filters numbered futures based on days left to expiry. When there is missing data a contract can end up being the nth contract multiple times. Following routine eliminates this problem by checking the number of times a contract is used for each expiry and deleting all but the last occurence.\n",
    " - Some  expiry dates do not match other expiry calendars  [Vix Expirations](https://www.macroption.com/vix-expiration-calendar/#exceptions) (DONE)\n",
    "     \n",
    " First weekly expirations are 5 August 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_timestamps(vix_data, exp='expiry2'):\n",
    "    df = vix_data[exp].to_frame()\n",
    "    df['counter'] = (df[exp] != df[exp].shift()).mask(df[exp].isnull()).groupby(df[exp]).cumsum()\n",
    "    timestamps = df.groupby(exp).apply(max)[df.groupby(exp).apply(max) > 1].dropna()\n",
    "    return timestamps\n",
    "matching = [s for s in vix_data.columns if \"expiry\" in s]\n",
    "matching.remove('expiry1')\n",
    "for item in matching:\n",
    "    repeat_timestamps = repeated_timestamps(vix_data, exp=item)\n",
    "    digit = re.findall(\"\\d+\", item)[0]\n",
    "    match_columns = [s for s in vix_data.columns if digit in s]\n",
    "    for time_stamp in repeat_timestamps[item]:\n",
    "        bar = vix_data[vix_data[item] == time_stamp].index # index of expiries\n",
    "        max_index = max([i for i, x in enumerate(np.diff(bar) > 1) if x])\n",
    "        vix_data.loc[bar[:max_index + 1], match_columns] = np.nan\n",
    "write_feather(vix_data, feather_directory / 'vix_data.feather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
